{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIZTNH+8RGMg3WoAyCmk61",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandrastna/AI-for-ESG/blob/main/Notebooks/7_1_Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Thesis 7_1 – GPT-3.5 for Sentiment Analysis\n",
        "1 - OpenAI Batch Requests : Creating the prompt and 4 JSONL batches to use with OpenAI's batch endpoint."
      ],
      "metadata": {
        "id": "0WEc9-jwDeyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEGeRzWftFBp",
        "outputId": "94fd3372-615a-4129-8177-ccedef175e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.95.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Fichier chargé avec 47272 phrases\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47272/47272 [00:04<00:00, 10954.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier JSONL prêt pour la Batch API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Initial setup\n",
        "!pip install --upgrade openai pandas tqdm\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # Authorize access to Google Drive\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Thèse Master/Exports2/df_esg.csv')\n",
        "print(f\"✅ Fichier chargé avec {len(df)} phrases\")\n",
        "\n",
        "# Create JSONL file for batch API\n",
        "system_prompt = (\n",
        "    \"You are an assistant that performs sentiment classification for ESG-related sentences. \"\n",
        "    \"For each input, respond only with one of the following labels: 'positive', 'neutral', or 'negative'. \"\n",
        "    \"Use 'positive' if the sentence describes an improvement, benefit, or progress. \"\n",
        "    \"Use 'negative' if it describes controversies, problems, or deteriorations. \"\n",
        "    \"Use 'neutral' if it is descriptive without clear judgment or consequence.\"\n",
        ")\n",
        "\n",
        "#Save all requests in a single JSONL file\n",
        "with open(\"/content/batch_sentiment.jsonl\", \"w\") as f:\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        sentence = row[\"sentence\"].strip().replace(\"\\n\", \" \")\n",
        "        prompt = {\n",
        "            \"custom_id\": f\"row-{i}\",\n",
        "            \"method\": \"POST\",\n",
        "            \"url\": \"/v1/chat/completions\",\n",
        "            \"body\": {\n",
        "                \"model\": \"gpt-3.5-turbo-0125\",\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": sentence}\n",
        "                ],\n",
        "                \"max_tokens\": 1,\n",
        "                \"temperature\": 0\n",
        "            }\n",
        "        }\n",
        "        f.write(json.dumps(prompt) + \"\\n\")\n",
        "\n",
        "print(\"✅ Fichier JSONL prêt pour la Batch API.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the JSONL into 4 chunks for parallel batching."
      ],
      "metadata": {
        "id": "GVsRWjZ0D_VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Reload the ESG sentence dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Thèse Master/Exports2/df_esg.csv')\n",
        "print(f\"✅ Fichier chargé avec {len(df)} phrases\")\n",
        "\n",
        "# Reuse the same sentiment classification prompt\n",
        "system_prompt = (\n",
        "    \"You are an assistant that performs sentiment classification for ESG-related sentences. \"\n",
        "    \"For each input, respond only with one of the following labels: 'positive', 'neutral', or 'negative'. \"\n",
        "    \"Use 'positive' if the sentence describes an improvement, benefit, or progress. \"\n",
        "    \"Use 'negative' if it describes controversies, problems, or deteriorations. \"\n",
        "    \"Use 'neutral' if it is descriptive without clear judgment or consequence.\"\n",
        ")\n",
        "\n",
        "# Create output folder if it doesn’t exist\n",
        "os.makedirs(\"/content/batches_sentiment\", exist_ok=True)\n",
        "\n",
        "# Split the dataset into 4 equal parts\n",
        "n = len(df)\n",
        "chunks = [df.iloc[i:i + n // 4] for i in range(0, n, n // 4)]\n",
        "\n",
        "# Create 4 separate batch files in JSONL format\n",
        "for idx, chunk in enumerate(chunks):\n",
        "    output_path = f\"/content/batches_sentiment/batch_sentiment_part{idx+1}.jsonl\"\n",
        "    with open(output_path, \"w\") as f:\n",
        "        for i, row in tqdm(chunk.iterrows(), total=len(chunk), desc=f\"Batch {idx+1}\"):\n",
        "            prompt = {\n",
        "                \"custom_id\": f\"row-{idx}-{i}\",\n",
        "                \"method\": \"POST\",\n",
        "                \"url\": \"/v1/chat/completions\",\n",
        "                \"body\": {\n",
        "                    \"model\": \"gpt-3.5-turbo-0125\",\n",
        "                    \"messages\": [\n",
        "                        {\"role\": \"system\", \"content\": system_prompt},\n",
        "                        {\"role\": \"user\", \"content\": row[\"sentence\"]}\n",
        "                    ],\n",
        "                    \"max_tokens\": 1,\n",
        "                    \"temperature\": 0\n",
        "                }\n",
        "            }\n",
        "            f.write(json.dumps(prompt) + \"\\n\")\n",
        "    print(f\"✅ Fichier batch {idx+1} créé ➤ {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWIs09CDgA1Y",
        "outputId": "759295a9-53ed-44d9-947c-a8943c34a7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier chargé avec 47272 phrases\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 1: 100%|██████████| 11818/11818 [00:01<00:00, 10069.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier batch 1 créé ➤ /content/batches_sentiment/batch_sentiment_part1.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 2: 100%|██████████| 11818/11818 [00:01<00:00, 11503.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier batch 2 créé ➤ /content/batches_sentiment/batch_sentiment_part2.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 3: 100%|██████████| 11818/11818 [00:01<00:00, 10733.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier batch 3 créé ➤ /content/batches_sentiment/batch_sentiment_part3.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch 4: 100%|██████████| 11818/11818 [00:01<00:00, 10394.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier batch 4 créé ➤ /content/batches_sentiment/batch_sentiment_part4.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}