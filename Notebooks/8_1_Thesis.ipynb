{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiMeAeVy0GeSYaxV2FZ1Ym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandrastna/AI-for-ESG/blob/main/Notebooks/8_1_Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Thesis 8 - Model Benchmarking on ESG and Sentiment Classification\n",
        "\n",
        "Step 1 - Here we create a sample in order to test our classification models (in step 2) : FinBERT classification, BERT ESG pillar classifier, and GPT-3.5 sentiment analysis. The sample is called \"gold standard 150\", and it's manually balanced."
      ],
      "metadata": {
        "id": "966qogKXXZ8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📦 Imports\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the ESG dataframe (already annotated by models)\n",
        "file_path = \"/content/drive/MyDrive/Thèse Master/Exports2/df_esg_with_batch_results.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Keep only valid rows: with dominant ESG label AND a valid sentiment from GPT\n",
        "df = df[df[\"label_dominant\"].isin([\"environmental\", \"social\", \"governance\"])]\n",
        "df = df[df[\"sentiment_gpt_batch\"].isin([\"positive\", \"neutral\", \"negative\"])]\n",
        "\n",
        "# Sample 50 rows per sentiment for initial balance\n",
        "df_pos = df[df[\"sentiment_gpt_batch\"] == \"positive\"].sample(n=50, random_state=1)\n",
        "df_neu = df[df[\"sentiment_gpt_batch\"] == \"neutral\"].sample(n=50, random_state=2)\n",
        "df_neg = df[df[\"sentiment_gpt_batch\"] == \"negative\"].sample(n=50, random_state=3)\n",
        "\n",
        "# Combine the 3 sentiment samples into one dataset\n",
        "df_sample = pd.concat([df_pos, df_neu, df_neg])\n",
        "\n",
        "# Ensure minimum of 50 samples per ESG pillar (E, S, G), complete if needed\n",
        "def add_missing_pillar(df_sample, full_df, label_value, min_count):\n",
        "    current_count = (df_sample[\"label_dominant\"] == label_value).sum()\n",
        "    if current_count >= min_count:\n",
        "        return df_sample\n",
        "    missing_n = min_count - current_count\n",
        "    # Add new samples for the underrepresented pillar, avoiding duplicates\n",
        "    extra = full_df[(full_df[\"label_dominant\"] == label_value) & (~full_df[\"sentence\"].isin(df_sample[\"sentence\"]))].sample(n=missing_n, random_state=42)\n",
        "    print(f\"⚠️ Ajout de {missing_n} phrases pour pilier {label_value}\")\n",
        "    return pd.concat([df_sample, extra])\n",
        "\n",
        "df_sample = add_missing_pillar(df_sample, df, \"environmental\", 50)\n",
        "df_sample = add_missing_pillar(df_sample, df, \"social\", 50)\n",
        "df_sample = add_missing_pillar(df_sample, df, \"governance\", 50)\n",
        "\n",
        "# Ensure all document types are represented\n",
        "doc_types_needed = [\"Annual Report\", \"Sustainability Report\", \"Earnings Call Transcript\", \"Integrated Report\", \"Half-Year Report\"]\n",
        "missing_doc_types = set(doc_types_needed) - set(df_sample[\"document_type\"].unique())\n",
        "for doc_type in missing_doc_types:\n",
        "    extra = df[df[\"document_type\"] == doc_type].sample(n=1, random_state=42)\n",
        "    print(f\"⚠️ Ajout d’un doc manquant : {doc_type}\")\n",
        "    df_sample = pd.concat([df_sample, extra])\n",
        "\n",
        "# Ensure all companies are represented at least once\n",
        "missing_companies = set(df[\"company\"].unique()) - set(df_sample[\"company\"].unique())\n",
        "if missing_companies:\n",
        "    print(f\"⚠️ Ajout de {len(missing_companies)} entreprises manquantes\")\n",
        "    extra = df[df[\"company\"].isin(missing_companies)].groupby(\"company\").head(1)\n",
        "    df_sample = pd.concat([df_sample, extra])\n",
        "\n",
        "# Final cleaning steps\n",
        "df_sample = df_sample.drop_duplicates(subset=[\"sentence\"])\n",
        "df_sample = df_sample.sample(n=min(150, len(df_sample)), random_state=999)\n",
        "\n",
        "# Add columns to be filled by human annotator\n",
        "df_sample[\"sentiment_humain\"] = \"\"\n",
        "df_sample[\"esg_label_humain\"] = \"\"\n",
        "\n",
        "# Export to Excel\n",
        "output_path = \"/content/drive/MyDrive/Thèse Master/Exports2/df_gold_standard_final_150.xlsx\"\n",
        "df_sample.to_excel(output_path, index=False)\n",
        "print(f\"\\n✅ Échantillon final exporté ici : {output_path}\")\n",
        "\n",
        "# Final checks\n",
        "print(\"\\n📌 Nb total de phrases :\", len(df_sample))\n",
        "\n",
        "# Add boolean flags for ESG pillar verification\n",
        "df_sample[\"is_E\"] = df_sample[\"label_dominant\"] == \"environmental\"\n",
        "df_sample[\"is_S\"] = df_sample[\"label_dominant\"] == \"social\"\n",
        "df_sample[\"is_G\"] = df_sample[\"label_dominant\"] == \"governance\"\n",
        "\n",
        "print(\"🔎 Nb de phrases E (is_E) :\", df_sample[\"is_E\"].sum())\n",
        "print(\"🔎 Nb de phrases S (is_S) :\", df_sample[\"is_S\"].sum())\n",
        "print(\"🔎 Nb de phrases G (is_G) :\", df_sample[\"is_G\"].sum())\n",
        "\n",
        "# Document type coverage\n",
        "print(\"📁 Types de documents couverts :\", df_sample[\"document_type\"].nunique())\n",
        "print(\"📁 Documents présents :\", df_sample[\"document_type\"].unique())\n",
        "\n",
        "# Company representation\n",
        "print(\"🏢 Nombre d’entreprises présentes :\", df_sample[\"company\"].nunique())\n",
        "\n",
        "# Sentiment distribution\n",
        "df_sample = df_sample.rename(columns={\"sentiment_gpt_batch\": \"sent_label\"})  # pour compatibilité avec ancien nom\n",
        "print(\"\\n🎯 Répartition des sentiments dans l'échantillon :\")\n",
        "print(df_sample[\"sent_label\"].value_counts())\n",
        "\n",
        "# Sentiment percentages\n",
        "print(\"\\n📈 Pourcentages :\")\n",
        "proportions = (df_sample[\"sent_label\"].value_counts(normalize=True) * 100).round(2).astype(str) + \" %\"\n",
        "print(proportions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cCHAaXD24Dn",
        "outputId": "5dc38c73-e7bd-4d52-fdf2-a0be8b6b8637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "⚠️ Ajout de 20 phrases pour pilier social\n",
            "⚠️ Ajout de 35 phrases pour pilier governance\n",
            "\n",
            "✅ Échantillon final exporté ici : /content/drive/MyDrive/Thèse Master/Exports2/df_gold_standard_final_150.xlsx\n",
            "\n",
            "📌 Nb total de phrases : 150\n",
            "🔎 Nb de phrases E (is_E) : 77\n",
            "🔎 Nb de phrases S (is_S) : 38\n",
            "🔎 Nb de phrases G (is_G) : 35\n",
            "📁 Types de documents couverts : 6\n",
            "📁 Documents présents : ['Integrated Report' 'Sustainability Report' 'Annual Report'\n",
            " 'Earnings Call Transcript' 'Half-Year Report' 'Governance Report']\n",
            "🏢 Nombre d’entreprises présentes : 3\n",
            "\n",
            "🎯 Répartition des sentiments dans l'échantillon :\n",
            "sent_label\n",
            "positive    56\n",
            "neutral     55\n",
            "negative    39\n",
            "Name: count, dtype: int64\n",
            "\n",
            "📈 Pourcentages :\n",
            "sent_label\n",
            "positive    37.33 %\n",
            "neutral     36.67 %\n",
            "negative     26.0 %\n",
            "Name: proportion, dtype: object\n"
          ]
        }
      ]
    }
  ]
}